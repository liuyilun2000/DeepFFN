{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ade5db43-e394-4e83-b837-f67e10aee999",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import copy\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "from pathlib import Path\n",
    "from typing import List, Optional, Union\n",
    "\n",
    "import requests\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import Sequential\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tqdm.auto import tqdm\n",
    "from safetensors import safe_open\n",
    "from safetensors.torch import load_file, save_file\n",
    "\n",
    "from datasets import load_dataset, Dataset\n",
    "from itertools import islice\n",
    "import wandb\n",
    "\n",
    "from multiprocessing import cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66b27cdf-5c35-4612-abf8-b8de830c6d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModel,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoProcessor,\n",
    "    AutoTokenizer,\n",
    "    LlamaTokenizer,\n",
    "    AutoModelForImageClassification,\n",
    "    AutoModelForSequenceClassification,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2705a5b6-751b-43e0-9202-49686e02df97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DeepFFNRoBERTa.configuration_roberta import DeepFFNRoBERTaConfig\n",
    "from DeepFFNRoBERTa.modelling_roberta import (\n",
    "    DeepFFNRobertaModel,\n",
    "    DeepFFNRobertaForSequenceClassification,\n",
    ")\n",
    "\n",
    "AutoConfig.register(\"deepffn-roberta\", DeepFFNRoBERTaConfig)\n",
    "AutoModel.register(DeepFFNRoBERTaConfig, DeepFFNRobertaModel)\n",
    "AutoModelForSequenceClassification.register(DeepFFNRoBERTaConfig, DeepFFNRobertaForSequenceClassification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0efd5f85-add0-45de-b7d1-b7488b9502e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = DeepFFNRoBERTaConfig(\n",
    "    hidden_size=768,\n",
    "    intermediate_size=4*768,\n",
    "    num_hidden_layers=12,\n",
    "    num_attention_heads=12,\n",
    "    num_key_value_heads=12,\n",
    "    num_mlp_layers=1,\n",
    ")\n",
    "model = DeepFFNRobertaForSequenceClassification(\n",
    "    config\n",
    ")\n",
    "# model = DeepFFNLlamaForCausalLM(config)\n",
    "# model = model.to(torch.bfloat16)\n",
    "# os.makedirs(\"DeepFFNLLaMA\", exist_ok=True)\n",
    "# model.save_pretrained(\"DeepFFNLLaMA\")\n",
    "# config.save_pretrained(\"DeepFFNLLaMA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "762353b8-0310-427d-b982-95507d57e59c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepFFNRobertaForSequenceClassification(\n",
       "  (roberta): DeepFFNRobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(512, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): DeepFFNRobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x DeepFFNRobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediates): ModuleList(\n",
       "            (0): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "          )\n",
       "          (outputs): ModuleList(\n",
       "            (0): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b546f7-1de0-4fee-a4c6-47f9b5001e92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
